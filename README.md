# toxicity_analyzer
The Detoxify model is a popular pre-trained deep learning model used for detecting and analyzing toxic language in text.  It was developed by researchers and is based on the BERT (Bidirectional Encoder Representations from Transformers) architecture. The model is fine-tuned for tasks like identifying toxicity, severe toxicity, obscene language, threats, insults, and identity-based hate.
